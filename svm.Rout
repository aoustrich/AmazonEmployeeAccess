
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(tidymodels)
── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──
✔ broom        1.0.5     ✔ recipes      1.0.8
✔ dials        1.2.0     ✔ rsample      1.2.0
✔ dplyr        1.1.3     ✔ tibble       3.2.1
✔ ggplot2      3.4.3     ✔ tidyr        1.3.0
✔ infer        1.0.5     ✔ tune         1.1.2
✔ modeldata    1.2.0     ✔ workflows    1.1.3
✔ parsnip      1.1.1     ✔ workflowsets 1.0.1
✔ purrr        1.0.2     ✔ yardstick    1.2.0
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Use tidymodels_prefer() to resolve common conflicts.
> library(tidyverse)
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ forcats   1.0.0     ✔ readr     2.1.4
✔ lubridate 1.9.3     ✔ stringr   1.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ readr::col_factor() masks scales::col_factor()
✖ purrr::discard()    masks scales::discard()
✖ dplyr::filter()     masks stats::filter()
✖ stringr::fixed()    masks recipes::fixed()
✖ dplyr::lag()        masks stats::lag()
✖ readr::spec()       masks yardstick::spec()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
> library(vroom)

Attaching package: ‘vroom’

The following objects are masked from ‘package:readr’:

    as.col_spec, col_character, col_date, col_datetime, col_double,
    col_factor, col_guess, col_integer, col_logical, col_number,
    col_skip, col_time, cols, cols_condense, cols_only, date_names,
    date_names_lang, date_names_langs, default_locale, fwf_cols,
    fwf_empty, fwf_positions, fwf_widths, locale, output_column,
    problems, spec

The following object is masked from ‘package:yardstick’:

    spec

The following object is masked from ‘package:scales’:

    col_factor

> library(embed)
> library(kernlab)

Attaching package: ‘kernlab’

The following object is masked from ‘package:purrr’:

    cross

The following object is masked from ‘package:ggplot2’:

    alpha

The following object is masked from ‘package:scales’:

    alpha

> library(parallel)
> 
> 
> # Read in Data and prep export function ----------------------------------
> 
> train <- vroom("train.csv")
Rows: 32769 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): ACTION, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTN...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> test <- vroom("test.csv")
Rows: 58921 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): id, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTNAME,...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> train$ACTION <- as.factor(train$ACTION)
> 
> 
> predict_export <- function(workflowName, fileName){
+   preds <- workflowName %>%
+     predict(new_data = test, type="prob")
+   
+   submission <- preds %>% 
+     mutate(id=row_number()) %>% 
+     rename(Action = .pred_1) %>% 
+     select(3,2)
+   
+   directory = "./submissions/"
+   path = paste0(directory,fileName)
+   
+   vroom_write(submission, file = path, delim=',')
+ }
> 
> # Recipe ------------------------------------------------------------------
> 
> recipe.pca <- recipe(ACTION ~ ., data = train) %>% 
+   step_mutate_at(all_numeric_predictors(), fn = factor) %>% 
+   step_other(all_nominal_predictors(), threshold = .001) %>% 
+   step_lencode_mixed(all_nominal_predictors(), outcome=vars(ACTION)) %>% 
+   step_normalize(all_numeric_predictors()) %>% 
+   step_pca(all_predictors(), threshold = 0.85) 
> 
> num_cores <- as.numeric(parallel::detectCores())#How many cores do I have?
> if (num_cores > 4){
+   num_cores = 10}
> cl <- makePSOCKcluster(num_cores)
> doParallel::registerDoParallel(cl)
> 
> prepped.pca <- prep(recipe.pca)
> bakedSetPCA <- bake(prepped.pca, new_data = train)
> 
> # unregister_dopar <- function() {
> #   env <- foreach:::.foreachGlobals
> #   rm(list=ls(name=env), pos=env)
> # }
> # 
> # unregister_dopar()
> 
> # Build Model and Workflow -----------------------------------------------
> 
> svmLinear <- svm_linear(cost=tune()) %>% 
+   set_mode("classification") %>%
+   set_engine("kernlab")
> 
> svmWF <- workflow() %>% 
+   add_recipe(recipe.pca) %>% 
+   add_model(svmLinear)
> 
> # Cross Validation --------------------------------------------------------
> 
> ## Create tuning grid and folds
> svmGrid <- grid_regular(cost(),levels = 10)
> svmFolds <- vfold_cv(train, v=5, repeats=1)
> 
> ## Run cross validation
> svmCVstart <- proc.time()
> # svmCVresults <- svmWF %>%
> #   tune_grid(resamples=svmFolds,
> #             grid=svmGrid,
> #             metrics=metric_set(roc_auc))
> 
> svmCVresults <- svmWF %>%
+   tune_grid(resamples=svmFolds,
+             grid=svmGrid,
+             metrics=metric_set(roc_auc))
> 
> proc.time()-svmCVstart
    user   system  elapsed 
   1.076    4.461 5800.768 
> 
> 
> # Fitting the best model --------------------------------------------------
> 
> ## Select the best tuned model
> svmBestTune <- svmCVresults %>% 
+   select_best("roc_auc")
> 
> # finalize workflow and fit
> svmFinal <- svmWF %>% 
+   finalize_workflow(svmBestTune) %>% 
+   fit(train)
 Setting default kernel parameters  
maximum number of iterations reached 0.01946811 -0.0136798> 
> 
> # Export Data -------------------------------------------------------------
> predict_export(svmFinal,"svmLinear.csv")
> 
> stopCluster(cl)
> 
> proc.time()
    user   system  elapsed 
 145.100   14.988 5920.123 
